<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>隐秀 | seriouszyx</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://seriouszyx.github.io/"/>
  <updated>2019-03-08T09:03:03.576Z</updated>
  <id>https://seriouszyx.github.io/</id>
  
  <author>
    <name>Yixiang Zhao</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>使用Forking工作流提交作业</title>
    <link href="https://seriouszyx.github.io/2019/03/08/%E4%BD%BF%E7%94%A8Forking%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%8F%90%E4%BA%A4%E4%BD%9C%E4%B8%9A.html"/>
    <id>https://seriouszyx.github.io/2019/03/08/使用Forking工作流提交作业.html</id>
    <published>2019-03-08T05:23:13.000Z</published>
    <updated>2019-03-08T09:03:03.576Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><h2 id="工作方式"><a href="#工作方式" class="headerlink" title="工作方式"></a>工作方式</h2><blockquote><p>  在讲解之前先说明一下，下文中的<code>你们</code>指代码贡献者，<code>我</code>指项目维护者。</p></blockquote><p><code>Forking</code> 工作流和其他工作流有根本的不同。 这种工作流不是使用单个服务端仓库作为『中央』代码基线，而是让各个开发者都有一个服务端仓库。 这意味着各个代码贡献者（你们）有2个 Git 仓库而不是1个：一个本地私有的（这里的本地私有不是指电脑上的本地，而是指你们 GitHub 账号下的远程仓库），另一个服务端公开的（指我的 GitHub 账号下的远程仓库）。</p><p><img src="https://raw.githubusercontent.com/seriouszyx/PicBed/master/img/git-workflows-forking.png" width="500" hegiht="313"></p><p>Forking 工作流的一个主要优势是，贡献的代码可以被集成，而不需要所有人都能 push 代码到仅有的中央仓库（我的远程仓库）中。 开发者 push 到自己的服务端仓库，而只有项目维护者才能 push 到正式仓库。 这样项目维护者可以接受任何开发者的提交，但无需给他正式代码库的写权限。</p><p>效果就是一个分布式的工作流，能为大型、自发性的团队（包括了不受信的第三方）提供灵活的方式来安全的协作。 也让这个工作流成为开源项目的理想工作流。</p><h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><h3 id="项目维护者初始化正式仓库"><a href="#项目维护者初始化正式仓库" class="headerlink" title="项目维护者初始化正式仓库"></a>项目维护者初始化正式仓库</h3><p><img src="https://raw.githubusercontent.com/seriouszyx/PicBed/master/img/git-workflows-forking-1.png" alt=""></p><p>和任何使用 Git 项目一样，第一步是创建在服务器上一个正式仓库，让所有团队成员都可以访问到。 通常这个仓库也会作为项目维护者的<a href="https://github.com/seriouszyx/Java-beginner" target="_blank" rel="noopener">公开仓库</a>。 </p><p>这个步骤由我来完成。</p><h3 id="开发者-fork-正式仓库"><a href="#开发者-fork-正式仓库" class="headerlink" title="开发者 fork 正式仓库"></a>开发者 <code>fork</code> 正式仓库</h3><p><img src="https://raw.githubusercontent.com/seriouszyx/PicBed/master/img/git-workflows-forking-2.png" alt=""></p><p>其它所有的开发（你们）需要 fork 正式仓库，fork 操作基本上就只是一个服务端的克隆。GitHub 有 fork 按钮只需点击就可以完成 fork 操作。</p><p>这一步完成后，每个开发者都在服务端（你们 GitHub 账号下）有一个自己的仓库。</p><h3 id="开发者克隆自己-fork-出来的仓库"><a href="#开发者克隆自己-fork-出来的仓库" class="headerlink" title="开发者克隆自己 fork 出来的仓库"></a>开发者克隆自己 <code>fork</code> 出来的仓库</h3><p><img src="https://raw.githubusercontent.com/seriouszyx/PicBed/master/img/git-workflows-forking-3.png" alt=""></p><p>下一步，各个开发者要克隆自己的公开仓库（是你们 GitHub 账号下的仓库，不是我账号下的），用熟悉的 git clone 命令。</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">git clone https://user@bitbucket.org/user/repo.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>Forking 工作流需要2个远程别名 —— 一个指向正式仓库，另一个指向开发者自己的服务端仓库。别名的名字可以任意命名，常见的约定是使用 origin 作为远程克隆的仓库的别名 （这个别名会在运行 git clone 自动创建），upstream（上游）作为正式仓库的别名。</p><p>当然，在没有足够熟悉之前，我建议你们用这种常见的命名方式。</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">git remote add upstream https://github.com/seriouszyx/Java-beginner.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>需要你们自己用上面的命令创建 upstream 别名，这里的 upstream 可以理解为一个引用指向了正式仓库（我账号下的仓库）。这样可以简单地保持本地仓库和正式仓库的同步更新。</p><h3 id="开发者开发自己的功能"><a href="#开发者开发自己的功能" class="headerlink" title="开发者开发自己的功能"></a>开发者开发自己的功能</h3><p><img src="https://raw.githubusercontent.com/seriouszyx/PicBed/master/img/git-workflows-forking-4.png" alt=""></p><p>为了避免冲突的产生，你们需要建立一个自己的分支，在分支上进行操作：</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">git checkout -b some-feature<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>some-future</code> 是分支名，你可以按照你喜欢的方式命名，不过建议你们命名为自己的姓名首字母缩写。 如果是我的话，我就会像下面这样命名：</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">git checkout -b zyx<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注意一点，除了第一次，以后进行分支的切换时不需要加 <code>-b</code>。</p><p>现在你就在自己的分支上处理代码，</p><h3 id="开发者发布自己的功能"><a href="#开发者发布自己的功能" class="headerlink" title="开发者发布自己的功能"></a>开发者发布自己的功能</h3><p>一旦开发者准备好了分享新功能（完成作业后），需要做二件事。 首先，通过 push 他的贡献代码到自己的公开仓库中，让其它的开发者都可以访问到。 他的origin 远程别名应该已经有了，所以要做的就是：</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">git add .git commit -m "balabala"git push origin feature-branch<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>这里最大的不同是 push 命令，你需要 push 的不是 master，而是你自己新建立的分支 <code>some-future</code>。</p><p>第二件事，开发者要通知项目维护者，想要合并他的新功能到正式库中。 GitHub 提供了 Pull Request 按钮（在你们自己仓库的页面刷新会出现），弹出表单让你指定哪个分支要合并到正式仓库。 一般你会想集成你的功能分支到上游远程仓库的master分支中。</p><h3 id="项目维护者集成开发者的功能"><a href="#项目维护者集成开发者的功能" class="headerlink" title="项目维护者集成开发者的功能"></a>项目维护者集成开发者的功能</h3><p><img src="https://raw.githubusercontent.com/seriouszyx/PicBed/master/img/git-workflows-forking-6.png" alt=""></p><p>这一步需要我来操作，你们可以大致看一下了解整个流程。</p><p>当项目维护者收到pull request，他要做的是决定是否集成它到正式代码库中。有二种方式来做：</p><p>1.直接在pull request中查看代码<br>2.pull代码到他自己的本地仓库，再手动合并</p><p>第一种做法更简单，维护者可以在GUI中查看变更的差异，做评注和执行合并。 但如果出现了合并冲突，需要第二种做法来解决。这种情况下，维护者需要从开发者的服务端仓库中 fetch 功能分支， 合并到他本地的 master 分支，解决冲突：</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">git fetch https://bitbucket.org/user/repo feature-branch# 查看变更git checkout mastergit merge FETCH_HEAD<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>变更集成到本地的master分支后，维护者要push变更到服务器上的正式仓库，这样其它的开发者都能访问到：</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">git push origin master<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注意，维护者的origin是指向他自己公开仓库的，即是项目的正式代码库。到此，<strong>开发者的贡献完全集成到了项目中</strong>。</p><h3 id="开发者和正式仓库做同步"><a href="#开发者和正式仓库做同步" class="headerlink" title="开发者和正式仓库做同步"></a>开发者和正式仓库做同步</h3><p>由于正式代码库往前走了，其它的开发需要和正式仓库做同步。 </p><p>举例来说，你们有几个人交了作业，或者我发布了新的任务，正式仓库的内容就发生了改变，你们需要获取最新的信息的话，就需要<code>同步</code>。</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">git pull upstream master<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>git pull 是一个拉取分支更新的命令，upstream 指我的远程仓库的别名（之前的步骤中创建过），master 指我的远程仓库的分支名。</p><p><strong>注意，一定要先将自己的代码 push，我合并了之后，再 pull 拉取更新。</strong></p><hr><blockquote><p>参考：<br>  <a href="https://github.com/oldratlee/translations/blob/master/git-workflows-and-tutorials/workflow-forking.md" target="_blank" rel="noopener">git-workflows-and-tutorials</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h2 id=&quot;工作方式&quot;&gt;&lt;a href=&quot;#工作方式&quot; class=&quot;headerlink&quot; title=&quot;工作方式&quot;&gt;&lt;/a&gt;工作方式&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;  在讲解之前先说明一下，下文中的&lt;code&gt;你们&lt;/code
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>《Algorithms,Part 1》Programming Assignment 1: Percolation</title>
    <link href="https://seriouszyx.github.io/2019/01/06/%E3%80%8AAlgorithms-Part-1%E3%80%8BProgramming-Assignment-1-Percolation.html"/>
    <id>https://seriouszyx.github.io/2019/01/06/《Algorithms-Part-1》Programming-Assignment-1-Percolation.html</id>
    <published>2019-01-06T08:07:13.000Z</published>
    <updated>2019-03-04T11:25:33.336Z</updated>
    
    <content type="html"><![CDATA[<p>coursera 课程 《Algorithms,Part 1》第一周作业解答 —— 渗透模型。</p><a id="more"></a><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>Programming Assignment 1 是一个并查集的应用——渗透模型。</p><p><img src="https://i.loli.net/2019/01/06/5c31b84b6e708.png" alt="80D8C615-CF2F-4DDD-9A3B-7460DB13725F.png"></p><p>给定义一个 $n\times n$ 的矩阵（代表一个系统），黑色代表节点被堵住，白色代表节点已经打开。默认情况下所有节点都被堵住，如果某一个节点与第一行的节点相连（connected），那么它就是 <code>full</code> 的。如果最后一行任意一个节点与第一个行任意一个节点相连，那么整个系统就是 <code>percolation</code>。</p><p>假设每个节点打开的概率是 $p$，求整个系统 percolation 的阀值估计。</p><p><img src="https://i.loli.net/2019/01/06/5c31bf3d3b947.png" alt="26697FCC-2B43-47B2-A94C-049E697D325A.png"></p><p>对于这个问题，我们可以使用 <code>蒙特卡洛模拟(Monte Carlo simulation)</code>：</p><ul><li>所有的节点初始化为关闭（blocked）</li><li>重复以下步骤，直到系统实现 percolation<ul><li>在所有关闭的节点中随便选择一个</li><li>打开（open）这个节点</li></ul></li><li>此时打开的节点个数/总节点个数就是系统的阀值</li></ul><p>假设经过 $T$ 次实验，每次实验的阀值是 $x_t$，则平均值 $\bar x$ 和方差 $s^2$ 的计算公式如下：</p><script type="math/tex; mode=display">\bar x=\frac{x_1+x_2+\dots+x_T}{T}, s^2=\frac{(x_1-\bar x)^2+(x_2-\bar x)^2+\dots+(x_T-\bar x)^2}{T-1}</script><p>假设 $T$ 足够大，下面给出阀值估计的 $95\%$ 的置信区间：</p><p>$ \Bigg[ \bar x-\frac{1.96s}{\sqrt{T}}, x+\frac{1.96s}{\sqrt{T}} \Bigg] $</p><p>要求实现两个类。Percolation.java 使用给定的 <code>WeightedQuickUnionUF</code> 实现以下 API，用于对渗透模型进行操作。</p><pre class="line-numbers language-lang-java"><code class="language-lang-java">public class Percolation {   public Percolation(int n)                // create n-by-n grid, with all sites blocked   public    void open(int row, int col)    // open site (row, col) if it is not open already   public boolean isOpen(int row, int col)  // is site (row, col) open?   public boolean isFull(int row, int col)  // is site (row, col) full?   public     int numberOfOpenSites()       // number of open sites   public boolean percolates()              // does the system percolate?   public static void main(String[] args)   // test client (optional)}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>PercolationStas.java 使用设计好的 Percolation 类进行蒙特卡洛模拟，并计算平均值、方差、置信区间等。</p><pre class="line-numbers language-lang-java"><code class="language-lang-java">public class PercolationStats {   public PercolationStats(int n, int trials)    // perform trials independent experiments on an n-by-n grid   public double mean()                          // sample mean of percolation threshold   public double stddev()                        // sample standard deviation of percolation threshold   public double confidenceLo()                  // low  endpoint of 95% confidence interval   public double confidenceHi()                  // high endpoint of 95% confidence interval   public static void main(String[] args)        // test client (described below)}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>Robert Sedgewick 已经在 Lecture Slides 上提到了一种有效的解决方案，那就是构造虚拟两个节点，以判断整个系统是否是 percolation。</p><p><img src="https://i.loli.net/2019/01/06/5c31ec52650f8.png" alt="C1435870-4DB5-453B-B094-E4B51B9F0FFB.png"></p><p>这种方式相当高效，我之前想的一种方法就无奈超时，这样 <code>isFull()</code> 和 <code>percolation()</code> 方法都是常数时间复杂度，这要比遍历一行节点效率高得多，尤其是第二个类的运行时，遍历的方法大概两分钟才能跑出来结果，而虚拟节点只需要两三秒钟。</p><p>不过虚拟节点会出现 <code>回流</code> 问题，可以内置两个 WeightedQuickUnionUF 对象，分别用于 <code>isFull()</code> 和 <code>percolation()</code> 两种方法的记录。</p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p><a href="https://github.com/seriouszyx/Algorithms-solution/tree/master/course/Percolation/src" target="_blank" rel="noopener">源代码</a></p><p>好不容易冲到了 99，需要用 <code>FindBugs</code> 和 <code>CheckStyle</code> 保证代码质量。</p><p>有时间把需要注意的地方补充了。</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;coursera 课程 《Algorithms,Part 1》第一周作业解答 —— 渗透模型。&lt;/p&gt;
    
    </summary>
    
      <category term="知识总结" scheme="https://seriouszyx.github.io/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="coursera" scheme="https://seriouszyx.github.io/tags/coursera/"/>
    
      <category term="Algorithms" scheme="https://seriouszyx.github.io/tags/Algorithms/"/>
    
      <category term="Programming Assignment" scheme="https://seriouszyx.github.io/tags/Programming-Assignment/"/>
    
  </entry>
  
  <entry>
    <title>大数据学习 | 初识 Hadoop</title>
    <link href="https://seriouszyx.github.io/2018/12/25/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0-%E5%88%9D%E8%AF%86Hadoop.html"/>
    <id>https://seriouszyx.github.io/2018/12/25/大数据学习-初识Hadoop.html</id>
    <published>2018-12-25T04:39:24.000Z</published>
    <updated>2019-03-07T08:56:52.520Z</updated>
    
    <content type="html"><![CDATA[<p>最近想要了解一些前沿技术，不能一门心思眼中只有 web，因为我目前对 Java 语言及其生态相对熟悉，所以在网上搜集了 Hadoop 相关文章，并做了整合。</p><p>本篇文章在于对大数据以及 Hadoop 有一个直观的概念，并上手简单体验。</p><a id="more"></a><h2 id="Hadoop-基础概念"><a href="#Hadoop-基础概念" class="headerlink" title="Hadoop 基础概念"></a>Hadoop 基础概念</h2><p><code>Hadoop</code> 是一个用 Java 实现的开源框架，是一个分布式的解决方案，将大量的信息处理所带来的压力分摊到其他服务器上。</p><p>在了解各个名词之前，我们必须掌握一组概念。</p><h3 id="结构化数据-vs-非结构化数据"><a href="#结构化数据-vs-非结构化数据" class="headerlink" title="结构化数据 vs 非结构化数据"></a>结构化数据 vs 非结构化数据</h3><p><code>结构化数据</code>即行数据，存储在数据库里，可以用二维表结构来表达，例如：名字、电话、家庭住址等。</p><p>常见的结构化数据库为 mysql、sqlserver。</p><p><img src="https://i.loli.net/2018/12/30/5c287655d4f10.jpg" alt="zhhihu1.jpg"></p><p><code>非结构化数据库</code>是指其字段长度可变，并且每个字段的记录又可以由可重复或不可重复的子字段构成的数据库。无法用结构化的数据模型表示，例如：文档、图片、声音、视频等。在大数据时代，对非关系型数据库的需求日益增加，数据库技术相应地进入了“后关系数据库时代”。</p><p>非结构化数据库代表为 HBase、mongodb。</p><p><img src="https://i.loli.net/2018/12/30/5c2876565ece1.jpg" alt="v2-27e5113596ab21aae1d64516ef015100_1200x500.jpg"></p><p>可以大致归纳，结构化数据是先有结构、再有数据；非结构化数据是先有数据、再有结构。</p><p>Hadoop 是大数据存储和计算的开山鼻祖，现在大多数开源大数据框架都依赖 Hadoop 或者与它能很好地兼容，下面开始讲述 Hadoop 的相关概念。</p><h3 id="Hadoop-1-0-vs-Hadoop-2-0"><a href="#Hadoop-1-0-vs-Hadoop-2-0" class="headerlink" title="Hadoop 1.0 vs Hadoop 2.0"></a>Hadoop 1.0 vs Hadoop 2.0</h3><p><img src="https://i.loli.net/2018/12/27/5c242519227c9.png" alt="Hadoop-1-vs-Hadoop-2-Architecture.png"></p><h3 id="HDFS-和-MapReduce"><a href="#HDFS-和-MapReduce" class="headerlink" title="HDFS 和 MapReduce"></a>HDFS 和 MapReduce</h3><p>Hadoop 为解决<code>存储</code>和<code>分析</code>大量数据而生，所以这两部分也是 Hadoop 的狭义说法（广义指 Hadoop 生态）。HDFS 提供了一种安全可靠的分布式文件存储系统，MapReduce 提供了基于批处理模式的数据分析框架。</p><p><code>HDFS</code>（Hadoop Distributed File System）的设计本质上是为了大量的数据能横跨很多台机器，但是你看到的是一个文件系统而不是很多个文件系统。就好比访问 <code>/hdfs/tmp/file1</code> 的数据，引用的是一个文件路径，但是实际数据可能分布在很多机器上，当然 HDFS 为你管理这些数据，用户并不需要了解它如何管理。</p><p>关于 <code>MapReduce</code>，这里通过一个具体模型来解释。</p><p>考虑如果你要统计一个巨大的文本文件存储在类似 HDFS 上，你想要知道这个文本里各个词的出现频率。你启动了一个 MapReduce 程序。Map 阶段，几百台机器同时读取这个文件的各个部分，分别把各自读到的部分分别统计出词频，产生类似（hello, 12100次），（world，15214次）等等这样的 Pair（我这里把 Map 和 Combine 放在一起说以便简化）；这几百台机器各自都产生了如上的集合，然后又有几百台机器启动 Reduce 处理。Reducer 机器 A 将从 Mapper 机器收到所有以 A 开头的统计结果，机器 B 将收到 B 开头的词汇统计结果（当然实际上不会真的以字母开头做依据，而是用函数产生 Hash 值以避免数据串化。因为类似 X 开头的词肯定比其他要少得多，而你不希望数据处理各个机器的工作量相差悬殊）。然后这些Reducer将再次汇总，（hello，12100）＋（hello，12311）＋（hello，345881）= （hello，370292）。每个 Reducer 都如上处理，你就得到了整个文件的词频结果。</p><p>这就是一个简单的 <code>WordCount</code> 的例子，Map+Reduce 这种简单模型暴力好用，不过很笨重，关于更高效的解决方法，以后再详细描述。</p><h3 id="Hadoop-构建模块"><a href="#Hadoop-构建模块" class="headerlink" title="Hadoop 构建模块"></a>Hadoop 构建模块</h3><p>下面从底层实现的角度解释 HDFS 和 MapReduce 的一些概念。</p><p><code>NameNode</code> 是 Hadoop 守护进程中最重要的一个。NameNode 位于 HDFS 的主端，指导 DataNode 执行底层的 IO 任务。NameNode 的运行消耗大量内存和 IO 资源，所以 NameNode 服务器不会同时是 DataNode 或 TaskTracker。</p><p>NameNode 和 <code>DataNode</code> 为主/从结构（Master/Slave）。每一个集群上的从节点都会驻留一个 DataNode 守护进程，来执行分布式文件系统的繁重工作，将 HDFS 数据块读取或者写入到本地文件系统的实际文件中。当希望对 HDFS 文件进行读写时，文件被分割为多个块，由NameNode 告知客户端每个数据块驻留在那个 DataNode。客户端直接与 DataNode 守护进程通信，来处理与数据块相对应的本地文件。</p><p><code>SNN</code>（Scondary NameNode）是监测 HDFS 集群状态的辅助守护进程。SNN 快照有助于加少停机的时间并降低数据丢失的风险。</p><p><code>JobTracker</code> 守护进程是应用程序和 Hadoop 之间的纽带。一旦提交代码到集群上，JobTracker 就会确定执行计划，包括决定处理哪些文件，为不同的任务分配节点以及监控所有任务的运行。如果任务失败，JobTracker 将自动重启任务，但所分配的节点可能会不同，同时受到预定义的重试次数限制。每一个Hadoop集群只有一个JobTracker守护进程，它通常运行在服务器集群的主节点上。</p><p>JobTracker 和 <code>TaskTracker</code> 也是主/从结构。JobTracker 作为主节点，监测 MapReduce 作业的整个执行过程，同时，TaskTracker 管理各个任务在每个从节点上的执行情况。TaskTracker 的一个职责就是负责持续不断地与 JobTracker 通讯。如果 JobTracker 在指定的时间内没有收到来自 TaskTracker 的心跳，它会假定 TaskTracker 已经崩溃了，进而重新提交相应的任务到集群的其他节点中。</p><h2 id="尝试使用-Hadoop"><a href="#尝试使用-Hadoop" class="headerlink" title="尝试使用 Hadoop"></a>尝试使用 Hadoop</h2><p><code>Hadoop 安装</code>可以直接看官方文档，或是 Google 一些不错的教程，比如 <a href="https://chu888chu888.gitbooks.io/hadoopstudy/content/Content/4/chapter0401.html" target="_blank" rel="noopener">Hadoop 的安装</a>、<a href="https://www.jianshu.com/p/de7eb61c983a" target="_blank" rel="noopener">Mac 系统安装Hadoop 2.7.3</a>。</p><p>按照操作配置 Hadoop 并成功运行，访问<code>localhost:50070</code> 和 <code>localhost:8088</code> 分别显示一下页面。</p><p><img src="https://i.loli.net/2018/12/27/5c2457210b58d.png" alt="90496E3D-A8FB-41CE-9FF0-3B962184AFAE.png"></p><p><img src="https://i.loli.net/2018/12/27/5c2457214a2e2.png" alt="1CBC323A-55DC-40AC-B258-3725DD0D4350.png"></p><p>运行<code>伪分布式</code>样例：</p><p><img src="https://i.loli.net/2018/12/27/5c24700c97c3a.png" alt="31D3E6A6-5864-4C6E-865E-AE576A64E647.png"></p><h3 id="HDFS-目录-文件操作命令"><a href="#HDFS-目录-文件操作命令" class="headerlink" title="HDFS 目录/文件操作命令"></a>HDFS 目录/文件操作命令</h3><p>HDFS 是一种文件系统，它可以将一个很大的数据集存储为一个文件，而大多数其他文件系统无力于这一点。Hadoop 也为它提供了一种与 Linux 命令类似的命令行工具，我们可以进行一些简单的操作。</p><p>Hadoop 的<code>文件命令</code>采取的形式为</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">hadoop fs -cmd <args><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中 cmd 为具体的文件命令，通常与 UNIX 对应的命令名相同，比如：</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">hadoop fs -lshadoop fs -mkdir /user/seriouszyxhadoop fs -lsr /hadoop fs -rm example.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>还有一些本地文件系统和 HDFS 交互的命令，也经常使用到。</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">hadoop fs -put example.txt /user/seriouszyxhadoop fs -get example.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="Hadoop-构建模块的原理"><a href="#Hadoop-构建模块的原理" class="headerlink" title="Hadoop 构建模块的原理"></a>Hadoop 构建模块的原理</h2><h3 id="MapReduce-如何分而治之"><a href="#MapReduce-如何分而治之" class="headerlink" title="MapReduce 如何分而治之"></a>MapReduce 如何分而治之</h3><p>MapReduce 是用来处理大规模数据的一个并行编程框架，采用了对数据“分而治之”的方法。</p><p><img src="https://i.loli.net/2018/12/30/5c28765631bc8.png" alt="40658-2de7c5066daf7ab1.png"></p><p>MapReduce 是一个离线计算框架，它将计算分为两个阶段，Map（并行处理输入数据）和 Reduce（对 Map 结果汇总）。其中 Map 和 Reduce 函数提供了两个高层接口，由用户去编程实现。</p><p>Map 的一般处理逻辑为：<strong>(k1;v1) ——&gt;map 处理——&gt;[(k2;v2)]</strong></p><p>Reduce 函数的一般处理逻辑是：<strong>(k2;[v2])——&gt;reduce 处理——&gt;[(k3;v3)]</strong></p><p>可以看出 map 处理的输出与 reduce 的输入并不完全相同，这是因为输入参数在进入 reduce 前，一般会将相同键 k2 下的所有值 v2 合并到一个集合中处理：<strong>[(k2;v2)]—-&gt;(k2;[v2])</strong>，这个过程叫 Combiner。</p><p>在经过 Map 和 Reduce 的抽象后，并行结构模型就变成了下面这样：</p><p><img src="https://i.loli.net/2018/12/30/5c28765664bab.png" alt="40658-df82b7a1775fac75.png"></p><p>上图中可以发现，中间有一个同步障（Barrier），其作用是等所有的 map 节点处理完后才进入 reduce，并且这个阶段同时进行数据加工整理过程（Aggregation &amp; Shuffle），以便 reduce 节点可以完全基于本节点上的数据计算最终结果。</p><p>不过这仍然不是完整的 MapReduce 模型，在上述框架图中，还少了两个步骤 Combiner 和 Partitioner。</p><p><img src="https://i.loli.net/2018/12/30/5c287656a01e5.png" alt="40658-39cc7b851195657c.png"></p><p>上述图以<code>词频统计（WordCount）</code>为例。</p><p><strong>Combiner</strong> 用来对中间结果数据网络传输进行优化，比如 map 处理完输出很多键值对后，某些键值对的键是相同的，Combiner 就会将相同的键合并，比如有两个键值对的键相同（good，1）和（good，2），便可以合成(good,3)。</p><p>这样，可以减少需要传输的中间结果数据量，打倒网络数据传输优化，因为 map 传给 reduce 是通过网络来传的。</p><p><strong>Partitioner</strong> 负责对中间结果进行分区处理。比如词频统计，将所有主键相同的键值对传输给同一个 Reduce 节点，以便 Reduce 节点不需要访问其他 Reduce 节点的情况下，一次性对分过来的中间结果进行处理。</p><h3 id="副本机制"><a href="#副本机制" class="headerlink" title="副本机制"></a>副本机制</h3><p>我们再说回 HDFS 诞生的原因，hdfs 由 Google 最先研发，其需求是单独一台计算机所能存储的空间是有限的，而随着计算机存储空间的加大，其价格是呈几何倍的增长。而 hdfs 架构在相对廉价的计算机上，以分布式的方式，这样想要扩大空间之遥增加集群的数量就可以了。</p><p>大量相对廉价的计算机，那么说明<strong>宕机</strong>就是一种必然事件，我们需要让数据避免丢失，就只用采取冗余数据存储，而具体的实现的就是<code>副本机制</code>。</p><p><img src="http://hadoop.apache.org/docs/r2.8.3/hadoop-project-dist/hadoop-hdfs/images/hdfsdatanodes.png" alt=""></p><p>hdfs 主要使用<code>三副本机制</code></p><ul><li>第一副本：如果上传节点是 DN，则上传该节点；如果上传节点是 NN，则随机选择 DN</li><li>第二副本：放置在不同机架的 DN 上</li><li>第三副本：放置在与第二副本相同机架的不同 DN 上</li></ul><p>除了极大程度地避免宕机所造成的数据损失，副本机制还可以在数据读取时进行数据校验。</p><h3 id="NameNode-在做些什么"><a href="#NameNode-在做些什么" class="headerlink" title="NameNode 在做些什么"></a>NameNode 在做些什么</h3><p>在 Hadoop 1.0 时代，Hadoop 两大核心组件 HDFS NameNode 和 JobTracker 都存在着单点问题，其中以 NameNode 最为严重。因为 <code>NameNode 保存了整个 HDFS 的元数据信息</code>，一旦 NameNode 挂掉，整个 HDFS 就无法访问，同时 Hadoop 生态系统中依赖于 HDFS 的各个组件，包括 MapReduce、Hive、Pig 以及 HBase 等也都无法正常工作，并且重新启动 NameNode 和进行数据恢复的过程也会比较耗时。</p><p>这些问题在给 Hadoop 的使用者带来困扰的同时，也极大地限制了 Hadoop 的使用场景，使得 Hadoop 在很长的时间内仅能用作离线存储和离线计算，无法应用到对可用性和数据一致性要求很高的在线应用场景中。</p><p>所幸的是，在 Hadoop2.0 中，HDFS NameNode 和 YARN ResourceManger(JobTracker 在 2.0 中已经被整合到 YARN ResourceManger 之中) 的单点问题都得到了解决，经过多个版本的迭代和发展，目前已经能用于生产环境。</p><p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/img001.png" alt=""></p><p>从上图中我们可以看到，有两台 NameNode——Active NameNode 和 Standby NameNode，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，只有主 NameNode 才能对外提供读写服务。</p><h3 id="Yarn"><a href="#Yarn" class="headerlink" title="Yarn"></a>Yarn</h3><p><code>Yarn</code> 是 Hadoop 集群的新一代资源管理系统。Hadoop 2.0 对 MapReduce 框架做了彻底的设计重构，我们称 Hadoop 2.0 中的 MapReduce 为 MRv2 或者 Yarn。</p><p><img src="https://i.loli.net/2018/12/30/5c28775f7eaa5.jpg" alt="20151029092726524 (2).jpg"></p><p>在 Hadoop 2.x 中，Yarn 把 job 的概念换成了 <code>application</code>，因为运行的应用不只是 MapReduce 了，还可能是其他应用，如一个 DAG（有向无环图 Directed Acyclic Graph，例如 Storm 应用）。</p><p>Yarn 另一个目标是扩展 Hadoop，使得它不仅仅可以支持 MapReduce 计算，还能很方便地管理诸如 Hive、Pig、Hbase、Spark/Shark 等应用。</p><p>这种新的架构设计能够使得各种类型的应用运行在 Hadoop 上面，并通过 Yarn 从系统层面进行统一的管理，也就是说，有了 Yarn，<strong>各种应用就可以互不干扰的运行在同一个 Hadoop 系统中</strong>，共享整个集群资源。</p><h3 id="ResourceManager-在做些什么"><a href="#ResourceManager-在做些什么" class="headerlink" title="ResourceManager 在做些什么"></a>ResourceManager 在做些什么</h3><p>刚刚提到的 Yarn 也采用了 Master/Slave 结构，其中 Master 为 <strong>ResourceManager</strong>，负责整个集群的资源管理与调度；Slave 实现为 <strong>NodeManager</strong>，负责单个节点的组员管理与任务启动。 </p><p>ResourceManager 是整个 Yarn 集群中最重要的组件之一，它的功能较多，包括 ApplicationMaster 管理（启动、停止等）、NodeManager 管理、Application 管理、状态机管理等。</p><p>ResourceManager 主要完成以下几个功能：</p><ul><li>与客户端交互，处理来自客户端的请求</li><li>启动和管理 ApplicationMaster，并在它失败时重新启动它</li><li>管理 NodeManager，接受来自 NodeManager 的资源管理汇报信息，并向 NodeManager 下达管理命令或把信息按照一定的策略分配给各个应用程序（ApplicationManager）等</li><li><strong>资源管理与调度，接受来自 ApplicationMaster 的资源申请请求，并为之分配资源（核心）</strong></li></ul><p>在 Master/Slave 架构中，ResourceManager 同样存在单点故障（高可用问题，High Availability）问题。为了解决它，通常采用热备方案，即集群中存在一个对外服务的 Active Master 和若干个处于就绪状态的 Standy Master，一旦 Active Master 出现故<br>障，立即采用一定的侧率选取某个 Standy Master 转换为 Active Master 以正常对外提供服务。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文介绍了 Hadoop 的相关概念，包括量大核心部件 HDFS 和 MapReduce，并对其进行了进一步剖析，Hadoop 2.0 的 Yarn 的简单介绍，以及一些问题的解决方法（如 HA）。</p><p>也通过配置第一次在本机上配置了 Hadoop 的运行环境，运行了伪分布式样例。</p><p>接下来会结合一个具体问题深入理解 Hadoop 的方方面面。</p><p><br></p><blockquote><p>  References:<br>   <a href="https://chu888chu888.gitbooks.io/hadoopstudy/content/" target="_blank" rel="noopener">大数据学习笔记</a><br>   <a href="https://zhuanlan.zhihu.com/p/26545566" target="_blank" rel="noopener">一文读懂大数据平台——写给大数据开发初学者的话!</a><br>  <a href="https://www.jianshu.com/p/ed6b35f52e3c" target="_blank" rel="noopener">Hadoop HDFS和MapReduce</a><br>  <a href="http://pangjiuzala.github.io/2015/08/03/HDFS%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/" target="_blank" rel="noopener">HDFS文件操作</a><br>  <a href="https://www.jianshu.com/p/35be7bdca902" target="_blank" rel="noopener">hadoop笔记4—MapReduce框架</a><br>  <a href="https://blog.csdn.net/suifeng3051/article/details/49486927" target="_blank" rel="noopener">Hadoop Yarn详解</a><br>  <a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/index.html" target="_blank" rel="noopener">Hadoop NameNode 高可用 (High Availability) 实现解析</a><br><a href="https://blog.csdn.net/zhangzhebjut/article/details/37730065" target="_blank" rel="noopener">Hadoop -YARN ResourceManager 剖析</a></p></blockquote><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近想要了解一些前沿技术，不能一门心思眼中只有 web，因为我目前对 Java 语言及其生态相对熟悉，所以在网上搜集了 Hadoop 相关文章，并做了整合。&lt;/p&gt;
&lt;p&gt;本篇文章在于对大数据以及 Hadoop 有一个直观的概念，并上手简单体验。&lt;/p&gt;
    
    </summary>
    
      <category term="知识总结" scheme="https://seriouszyx.github.io/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="大数据" scheme="https://seriouszyx.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Hadoop" scheme="https://seriouszyx.github.io/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>[总结|展望] 世界不会因为你的无知而停下脚步</title>
    <link href="https://seriouszyx.github.io/2018/12/10/%E6%80%BB%E7%BB%93-%E5%B1%95%E6%9C%9B-%E4%B8%96%E7%95%8C%E4%B8%8D%E4%BC%9A%E5%9B%A0%E4%B8%BA%E4%BD%A0%E7%9A%84%E6%97%A0%E7%9F%A5%E8%80%8C%E5%81%9C%E4%B8%8B%E8%84%9A%E6%AD%A5.html"/>
    <id>https://seriouszyx.github.io/2018/12/10/总结-展望-世界不会因为你的无知而停下脚步.html</id>
    <published>2018-12-10T14:18:05.000Z</published>
    <updated>2019-03-07T08:58:14.563Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Be the greatest, or nothing</strong>。</p><p>不久前接到这学期期末考试的时间安排表，没想到时间过得这么快。在我所认知的世界里，感到时光飞逝大概有两种原因：强烈热衷于某一事物而忘记时间和玩物丧志在不知不觉中荒废时间，我想，我属于后者。</p><p>这学期的我依旧在学习技术、忠于兴趣、力求做到更好，却又懒惰、贪心、自我怀疑、无所适从、对未来没有信心。</p><p>回首看来，我竟然如此疯狂，用这种态度对待生命中最宝贵的时光。</p><a id="more"></a><h2 id="期末安排"><a href="#期末安排" class="headerlink" title="期末安排"></a>期末安排</h2><p>对于本学期最大的弥补，我所能想到的就是好好准备期末考试，把绩点再冲上一个台阶。</p><p>实际上，我是相当讨厌单纯刷绩点这种行为，它大概是初高中应试教育所遗留的糟粕。每个学期，我都会把学习重心放在技术而非学院所开设的课程上，这并非我不重视基础，而是教学安排的确不完全适合我。</p><p>尤其是这学期，开了两门无用的语言课（Java、C#），而且教学质量较差，前几天一个水平较高的同学还跟我哭诉现在还敲不出来像样的 Java 代码。余下三门专业课（数字逻辑、离散、汇编）也平淡无奇，甚至有的老师让我想起了 <strong>PPT Reader</strong> 这个词。 </p><p>相比之下，我一位在相对较好的学校的同学这学期已经对算法和系统都有了不浅的认识，他们的硬件课教材是 CSAPP，作业也大概是 CMU 15-213 的改进版本。</p><p>事实上，现在说刷本学期绩点似乎是个荒唐的事情，毕竟我平时加分少的可怜，甚至旷课被逮到。我能做的，就是尽量在期末的考试中把成绩得到最高，这算是尽力了吧。</p><h2 id="比赛"><a href="#比赛" class="headerlink" title="比赛"></a>比赛</h2><p>大二的我开始接触更多的比赛，不过上学期也仅仅在四科竞赛中得到了 Java 组的一个奖项（还不确定）。是时候为我的简历增些光彩了，所以我报名了蓝桥杯的团队赛和个人赛，并开始了解 PAT。</p><p>假期我会以准备比赛和提升英语技能为主，尤其是个人赛，我计划尽力拿到国家级的奖项，团体赛目前不是特别了解，不好立 flag。在经历了四级的失望后，我决心拿出大量时间准备英语，特别是听力方面，假期我会进行一些安排。</p><p>包括下学期的几个比赛，大学生英语竞赛、数学建模校赛，我都会着手准备，并力争靠前的名次。</p><h2 id="项目"><a href="#项目" class="headerlink" title="项目"></a>项目</h2><p>讲真，作为走开发路线的我，目前的进展可以算得上很慢了。刚刚把 JavaWeb 的生态熟悉了一遍，可惜院里 Java 的项目太少，也没有得到合适的锻炼机会。不过下学期即便没有好的机会，我也会主动联系老师，真的不能再等了。</p><h2 id="展望"><a href="#展望" class="headerlink" title="展望"></a>展望</h2><p>大二接下来的日子对我大学生涯意义重大，我希望可以通过这段时间证明自己，暂时我不会再好高骛远，而是着手应对当下，我希望在大二结束的那一刻，再翻看这篇文章，能做到问心无愧。</p><blockquote><p>要像疯马一样奔跑，快，再快，没有人会等你，弗莱切说得很对，这世上最伤人的句子就是 Good job。<br>  Good job，哦，我做的还不错，我差不多可以了。<br>不不不！愿没有，你远未愤怒，也远未觉悟，你那些梦想和努力，不过是廉价童话里说说而已。</p><p>我们根本就没有努力到与人拼天赋的地位，而我们却像当然的，以为我们的失败只是因为缺乏运气。<br>我们就是弗莱切嘴里的 Mother fucker，而我们仍然沾沾自喜。<br>这世上的伟大，世上的成功，哪有一蹴而就。<br>所谓峰回路转，崖下秘籍，都是故事里哄骗读者的伎俩，而真实的世界，是要见血的。</p><p>残酷的励志，励志与鸡汤本来就是两种东西，真实的励志。就是打倒了，爬起来，浑身是血，又聋又瞎，成功的最后，很可能什么也得不到。<br>很可能，你也将早早死去。<br>但烈火是你点的，你说要烧一座山，就要做好烧死自己的觉悟。<br>大火降至。<br>Be the greatest, or nothing。</p><p>——朱炫  《爆裂鼓手》影评</p></blockquote><p><img src="https://i.loli.net/2018/12/10/5c0e74b9d6e0b.jpg" alt="" style="width:100%"></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;Be the greatest, or nothing&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;不久前接到这学期期末考试的时间安排表，没想到时间过得这么快。在我所认知的世界里，感到时光飞逝大概有两种原因：强烈热衷于某一事物而忘记时间和玩物丧志在不知不觉中荒废时间，我想，我属于后者。&lt;/p&gt;
&lt;p&gt;这学期的我依旧在学习技术、忠于兴趣、力求做到更好，却又懒惰、贪心、自我怀疑、无所适从、对未来没有信心。&lt;/p&gt;
&lt;p&gt;回首看来，我竟然如此疯狂，用这种态度对待生命中最宝贵的时光。&lt;/p&gt;
    
    </summary>
    
      <category term="人生苦旅" scheme="https://seriouszyx.github.io/categories/%E4%BA%BA%E7%94%9F%E8%8B%A6%E6%97%85/"/>
    
    
      <category term="大学生活" scheme="https://seriouszyx.github.io/tags/%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%B4%BB/"/>
    
      <category term="总结" scheme="https://seriouszyx.github.io/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>就决定是你了 | 为你的终端安装 Pokemon 皮肤</title>
    <link href="https://seriouszyx.github.io/2018/11/27/%E5%B0%B1%E5%86%B3%E5%AE%9A%E6%98%AF%E4%BD%A0%E4%BA%86-%E4%B8%BA%E4%BD%A0%E7%9A%84%E7%BB%88%E7%AB%AF%E5%AE%89%E8%A3%85-Pokemon-%E7%9A%AE%E8%82%A4.html"/>
    <id>https://seriouszyx.github.io/2018/11/27/就决定是你了-为你的终端安装-Pokemon-皮肤.html</id>
    <published>2018-11-27T04:21:08.000Z</published>
    <updated>2018-11-27T05:38:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>正值精灵宝可梦大热时期，在逛 GitHub 时发现了一个特别强的东西 —— <a href="https://github.com/LazoCoder/Pokemon-Terminal" target="_blank" rel="noopener">Pokemon-Terminal</a>，经过一顿折腾后，终于把终端打造成了这个样子 👇</p><p><img src="http://pi0evhi68.bkt.clouddn.com/A5592C04-B48F-47E4-BBB8-3BA763D5F668.png" alt="" style="width:100%"></p><a id="more"></a><h2 id="Pokemon-Terminal"><a href="#Pokemon-Terminal" class="headerlink" title="Pokemon-Terminal"></a>Pokemon-Terminal</h2><p>正值精灵宝可梦大热时期，在逛 GitHub 时发现了一个特别强的东西 —— <a href="https://github.com/LazoCoder/Pokemon-Terminal" target="_blank" rel="noopener">Pokemon-Terminal</a></p><p>这是一款美化终端的神器，将口袋妖怪与终端完美结合，先上几张图让大家感受一下：</p><p><img src="http://pi0evhi68.bkt.clouddn.com/Pokemon Terminal README md at master · LazoCoder Pokemon Terminal.png" alt="Pokemon Terminal README md at master · LazoCoder Pokemon Terminal"></p><p>它拥有 719 款 Pokemon 皮肤，可以根据编号或口袋妖怪名字（例如 pikachu）改变，支持 iTerm2、ConEmu、Terminology、Tilix 等终端，同时支持 Windows、MacOS、GNOME、Openbox 和 i3wm。</p><p>如果你也是个口袋迷，那么快来给你的终端安上这款皮肤吧！</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>本项目的 README 上有各种安装方法，这里以 macOS 为例。</p><p>首先确保你的电脑已经安装 3.6 及以上版本的 python（最好是 3.6），下面是下载地址</p><ul><li><a href="https://www.python.org/downloads/mac-osx/" target="_blank" rel="noopener">For Mac</a></li><li><a href="https://www.python.org/downloads/windows/" target="_blank" rel="noopener">For Windows</a></li><li><a href="https://askubuntu.com/a/865569" target="_blank" rel="noopener">For Ubuntu</a></li><li><a href="https://www.archlinux.org/packages/extra/x86_64/python/" target="_blank" rel="noopener">For Arch Linux</a></li></ul><p>确保有以下终端模拟器中的一种（我用的是 iTerm2）</p><ul><li><a href="https://iterm2.com/" target="_blank" rel="noopener">iTerm2</a></li><li><a href="https://conemu.github.io/" target="_blank" rel="noopener">ConEmu</a> or derivative (such as <a href="http://cmder.net/" target="_blank" rel="noopener">Cmder</a>)</li><li><a href="https://www.enlightenment.org/about-terminology" target="_blank" rel="noopener">Terminology</a></li><li><a href="https://gnunn1.github.io/tilix-web/" target="_blank" rel="noopener">Tilix</a></li></ul><p>可以使用以下几种方式安装</p><ul><li><a href="https://aur.archlinux.org/packages/pokemon-terminal-git/" target="_blank" rel="noopener">Arch Linux User Repository package (System-wide)</a> </li><li><a href="#pip-system-wide">pip (System-wide)</a></li><li><a href="#pip-per-user">pip (Per-User)</a></li><li><a href="#npm-per-user">npm (Per-User)</a></li><li><a href="#distutils-system-wide">Distutils (System-wide)</a></li></ul><p>这里我使用 npm 安装（确保有 node.js），因为比较简单。</p><p>在 iTerm 2 中输入以下命令</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">npm install --global pokemon-terminal<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>好了，这就安装成功了，是不是非常简单！</p><pre class="line-numbers language-lang-bash"><code class="language-lang-bash">$ pokemon pikachu<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>皮卡丘，就决定是你了!</p><h2 id="深度使用"><a href="#深度使用" class="headerlink" title="深度使用"></a>深度使用</h2><p>每次启动都想<code>自动随机</code>更换皮肤的话，可以像这样设置：</p><p><img src="http://pi0evhi68.bkt.clouddn.com/3806757A-C9B3-41AD-8D70-637CC9DFFF29.png" alt="3806757A-C9B3-41AD-8D70-637CC9DFFF29"></p><p>还有原项目给出的使用方法：</p><pre><code>usage: pokemon [-h] [-n NAME]               [-r [{kanto,johto,hoenn,sinnoh,unova,kalos} [{kanto,johto,hoenn,sinnoh,unova,kalos} ...]]]               [-l [0.xx]] [-d [0.xx]]               [-t [{normal,fire,fighting,water,flying,grass,poison,electric,ground,psychic,rock,ice,bug,dragon,ghost,dark,steel,fairy} [{normal,fire,fighting,water,flying,grass,poison,electric,ground,psychic,rock,ice,bug,dragon,ghost,dark,steel,fairy} ...]]]               [-ne] [-e] [-ss [X]] [-w] [-v] [-dr] [-c]               [id]Set a pokemon to the current terminal background or wallpaperpositional arguments:  id                    Specify the wanted pokemon ID or the exact (case                        insensitive) nameoptional arguments:  -h, --help            show this help message and exit  -c, --clear           Clears the current pokemon from terminal background                        and quits.Filters:  Arguments used to filter the list of pokemons with various conditions that  then will be picked  -n NAME, --name NAME  Filter by pokemon which name contains NAME  -r [{kanto,johto,hoenn,sinnoh,unova,kalos} [{kanto,johto,hoenn,sinnoh,unova,kalos} ...]], --region [{kanto,johto,hoenn,sinnoh,unova,kalos} [{kanto,johto,hoenn,sinnoh,unova,kalos} ...]]                        Filter the pokemons by region  -l [0.xx], --light [0.xx]                        Filter out the pokemons darker (lightness threshold                        lower) then 0.xx (default is 0.7)  -d [0.xx], --dark [0.xx]                        Filter out the pokemons lighter (lightness threshold                        higher) then 0.xx (default is 0.42)  -t [{normal,fire,fighting,water,flying,grass,poison,electric,ground,psychic,rock,ice,bug,dragon,ghost,dark,steel,fairy} [{normal,fire,fighting,water,flying,grass,poison,electric,ground,psychic,rock,ice,bug,dragon,ghost,dark,steel,fairy} ...]], --type [{normal,fire,fighting,water,flying,grass,poison,electric,ground,psychic,rock,ice,bug,dragon,ghost,dark,steel,fairy} [{normal,fire,fighting,water,flying,grass,poison,electric,ground,psychic,rock,ice,bug,dragon,ghost,dark,steel,fairy} ...]]                        Filter the pokemons by type.  -ne, --no-extras      Excludes extra pokemons (from the extras folder)  -e, --extras          Excludes all non-extra pokemonsMisc:  -ss [X], --slideshow [X]                        Instead of simply choosing a random pokemon from the                        filtered list, starts a slideshow (with X minutes of                        delay between pokemon) in the background with the                        pokemon that matched the filters  -w, --wallpaper       Changes the desktop wallpaper instead of the terminal                        background  -v, --verbose         Enables verbose output  -dr, --dry-run        Implies -v and doesn&#39;t actually changes either                        wallpaper or background after the pokemon has been                        chosenNot setting any filters will get a completely random pokemon</code></pre><p>举几个例子，可以根据口袋妖怪的名字改变皮肤</p><p><img src="https://i.imgur.com/DfA2lcd.gif" alt=""></p><p>同一款皮肤（部分）还可以改变不同的形态</p><p><img src="https://i.imgur.com/gdGUucu.gif" alt=""></p><p>还可以自定义图片之类的，自己摸索吧。</p><h2 id="终端美化"><a href="#终端美化" class="headerlink" title="终端美化"></a>终端美化</h2><p>作者建议更改终端默认的透明度的模糊程度，以达到更好的效果，可以像这样设置：</p><p><img src="https://i.imgur.com/xSZAGhL.png" alt=""></p><p>设置之后就会变成这个样子：</p><p><img src="https://i.imgur.com/82DAT97.jpg" alt=""></p><p>iTerm 2 的默认功能还是不够强大，可以配置 oh-my-zsh，安装字体库、插件等，如果有需要可以参考这篇文章 <a href="https://segmentfault.com/a/1190000014992947" target="_blank" rel="noopener">iTerm2 + Oh My Zsh 打造舒适终端体验</a>。</p><p>最后，安装配置了 iTerm 2 + oh-my-zsh + Pokemon-Terminal，你就拥有了像下面一样的终端。</p><p><img src="http://pi0evhi68.bkt.clouddn.com/404B150B-328D-4038-B142-06C0CDDEC40A.png" alt="404B150B-328D-4038-B142-06C0CDDEC40A"></p><p>Have fun !</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;正值精灵宝可梦大热时期，在逛 GitHub 时发现了一个特别强的东西 —— &lt;a href=&quot;https://github.com/LazoCoder/Pokemon-Terminal&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Pokemon-Terminal&lt;/a&gt;，经过一顿折腾后，终于把终端打造成了这个样子 👇&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://pi0evhi68.bkt.clouddn.com/A5592C04-B48F-47E4-BBB8-3BA763D5F668.png&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="折腾" scheme="https://seriouszyx.github.io/categories/%E6%8A%98%E8%85%BE/"/>
    
    
      <category term="折腾" scheme="https://seriouszyx.github.io/tags/%E6%8A%98%E8%85%BE/"/>
    
      <category term="Linux" scheme="https://seriouszyx.github.io/tags/Linux/"/>
    
      <category term="终端" scheme="https://seriouszyx.github.io/tags/%E7%BB%88%E7%AB%AF/"/>
    
      <category term="美化" scheme="https://seriouszyx.github.io/tags/%E7%BE%8E%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>IoC容器浅析及简单实现</title>
    <link href="https://seriouszyx.github.io/2018/11/25/IoC%E5%AE%B9%E5%99%A8%E6%B5%85%E6%9E%90%E5%8F%8A%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0.html"/>
    <id>https://seriouszyx.github.io/2018/11/25/IoC容器浅析及简单实现.html</id>
    <published>2018-11-25T06:43:04.000Z</published>
    <updated>2019-03-04T11:25:43.718Z</updated>
    
    <content type="html"><![CDATA[<p>Spring IoC 容器是 Spring 框架中最核心的部分，也是初学者难以理解的部分，对于这种关键的设计，简单实现一次能最大限度地加深理解，了解其中思想，对以后的开发也大有裨益。</p><a id="more"></a><h1 id="Spring-IoC-容器浅析及简单实现"><a href="#Spring-IoC-容器浅析及简单实现" class="headerlink" title="Spring IoC 容器浅析及简单实现"></a>Spring IoC 容器浅析及简单实现</h1><h2 id="Spring-IoC-概述"><a href="#Spring-IoC-概述" class="headerlink" title="Spring IoC 概述"></a>Spring IoC 概述</h2><p>原生的 JavaEE 技术中各个模块之间的联系较强，即<code>耦合度较高</code>。</p><p>比如完成一个用户的创建事务，视图层会创建业务逻辑层的对象，再在内部调用对象的方法，各个模块的<code>独立性很差</code>，如果某一模块的代码发生改变，其他模块的改动也会很大。</p><p>而 Spring 框架的核心——IoC（控制反转）很好的解决了这一问题。控制反转，即<code>某一接口具体实现类的选择控制权从调用类中移除，转交给第三方决定</code>，即由 Spring 容器借由 Bean 配置来进行控制。</p><p>可能 IoC 不够开门见山，理解起来较为困难。因此， Martin Fowler 提出了 DI（Dependency Injection，依赖注入）的概念来替代 IoC，即<code>让调用类对某一接口实现类的依赖关系由第三方（容器或写协作类）注入，以移除调用类对某一接口实现类的依赖</code>。</p><p>比如说， 上述例子中，视图层使用业务逻辑层的接口变量，而不需要真正 new 出接口的实现，这样即使接口产生了新的实现或原有实现修改，视图层都能正常运行。</p><p>从注入方法上看，IoC 主要划分为三种类型：构造函数注入、属性注入和接口注入。在开发过程中，一般使用<code>属性注入</code>的方法。</p><p>IoC 不仅可以实现<code>类之间的解耦</code>，还能帮助完成<code>类的初始化与装配工作</code>，让开发者从这些底层实现类的实例化、依赖关系装配等工作中解脱出出来，专注于更有意义的业务逻辑开发工作。</p><h2 id="Spring-IoC-简单实现"><a href="#Spring-IoC-简单实现" class="headerlink" title="Spring IoC 简单实现"></a>Spring IoC 简单实现</h2><p>下面实现了一个IoC容器的核心部分，简单模拟了IoC容器的基本功能。</p><p>下面列举出核心类：</p><p>Student.java</p><pre class="line-numbers language-lang-java"><code class="language-lang-java">/** * @ClassName Student * @Description 学生实体类 * @Author Yixiang Zhao * @Date 2018/9/22 9:19 * @Version 1.0 */public class Student {    private String name;    private String gender;    public void intro() {        System.out.println("My name is " + name + " and I'm " + gender + " .");    }    public String getName() {        return name;    }    public void setName(String name) {        this.name = name;    }    public String getGender() {        return gender;    }    public void setGender(String gender) {        this.gender = gender;    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>StuService.java</p><pre class="line-numbers language-lang-java"><code class="language-lang-java">/** * @ClassName StuService * @Description 学生Service * @Author Yixiang Zhao * @Date 2018/9/22 9:21 * @Version 1.0 */public class StuService {    private Student student;    public Student getStudent() {        return student;    }    public void setStudent(Student student) {        this.student = student;    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>beans.xml</p><pre class="line-numbers language-lang-xml"><code class="language-lang-xml"><?xml version="1.0" encoding="UTF-8"?><beans>    <bean id="Student" class="me.seriouszyx.pojo.Student">        <property name="name" value="ZYX"/>        <property name="gender" value="man"/>    </bean>    <bean id="StuService" class="me.seriouszyx.service.StuService">        <property ref="Student"/>    </bean></beans><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>下面是核心类 ClassPathXMLApplicationContext.java</p><pre class="line-numbers language-lang-java"><code class="language-lang-java">/** * @ClassName ClassPathXMLApplicationContext * @Description ApplicationContext的实现，核心类 * @Author Yixiang Zhao * @Date 2018/9/22 9:40 * @Version 1.0 */public class ClassPathXMLApplicationContext implements ApplicationContext {    private Map map = new HashMap();    public ClassPathXMLApplicationContext(String location) {        try {            Document document = getDocument(location);            XMLParsing(document);        } catch (Exception e) {            e.printStackTrace();        }    }    // 加载资源文件，转换成Document类型    private Document getDocument(String location) throws JDOMException, IOException {        SAXBuilder saxBuilder = new SAXBuilder();        return saxBuilder.build(this.getClass().getClassLoader().getResource(location));    }    private void XMLParsing(Document document) throws Exception {        // 获取XML文件根元素beans        Element beans = document.getRootElement();        // 获取beans下的bean集合        List beanList = beans.getChildren("bean");        // 遍历beans集合        for (Iterator iter = beanList.iterator(); iter.hasNext(); ) {            Element bean = (Element) iter.next();            // 获取bean的属性id和class，id为类的key值，class为类的路径            String id = bean.getAttributeValue("id");            String className = bean.getAttributeValue("class");            // 动态加载该bean代表的类            Object obj = Class.forName(className).newInstance();            // 获得该类的所有方法            Method[] methods = obj.getClass().getDeclaredMethods();            // 获取该节点的所有子节点，子节点存储类的初始化参数            List<Element> properties = bean.getChildren("property");            // 遍历，将初始化参数和类的方法对应，进行类的初始化            for (Element pro : properties) {                for (int i = 0; i < methods.length; i++) {                    String methodName = methods[i].getName();                    if (methodName.startsWith("set")) {                        String classProperty = methodName.substring(3, methodName.length()).toLowerCase();                        if (pro.getAttribute("name") != null) {                            if (classProperty.equals(pro.getAttribute("name").getValue())) {                                methods[i].invoke(obj, pro.getAttribute("value").getValue());                            }                        } else {                            methods[i].invoke(obj, map.get(pro.getAttribute("ref").getValue()));                        }                    }                }            }            // 将初始化完成的对象添加到HashMap中            map.put(id, obj);        }    }    public Object getBean(String name) {        return map.get(name);    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>最后进行测试</p><pre class="line-numbers language-lang-java"><code class="language-lang-java">public class MyIoCTest {    public static void main(String[] args) {        ApplicationContext context = new ClassPathXMLApplicationContext("beans.xml");        StuService stuService = (StuService) context.getBean("StuService");        stuService.getStudent().intro();    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>测试成功！</p><pre class="line-numbers language-lang-text"><code class="language-lang-text">My name is ZYX and I'm man .Process finished with exit code 0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><p>代码在我的 <a href="https://github.com/seriouszyx/LearnSpring/tree/master/mycode/SimpleIoC" target="_blank" rel="noopener">GitHub</a>开源，欢迎一起交流讨论。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>熟悉一个框架最好的方式，就是亲手实现它。这样不仅会深刻地认识到框架的工作原理，以后的使用也会更加得心应手。</p><p>此外，在实现的过程中，又会收获很多东西，就像实现 IoC 容器一样，不仅了解解析 XML 文件的 JDOM 工具，还加深了对 Java 反射的理解。在实际开发中，几乎没有任何地方需要用到反射这一技术，但在框架实现过程中，不懂反射则寸步难行。</p><blockquote><p>   更多的 Spring 学习心得请戳<a href="https://github.com/seriouszyx/LearnSpring" target="_blank" rel="noopener">Spring 框架学习</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Spring IoC 容器是 Spring 框架中最核心的部分，也是初学者难以理解的部分，对于这种关键的设计，简单实现一次能最大限度地加深理解，了解其中思想，对以后的开发也大有裨益。&lt;/p&gt;
    
    </summary>
    
      <category term="知识总结" scheme="https://seriouszyx.github.io/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="JavaWeb" scheme="https://seriouszyx.github.io/tags/JavaWeb/"/>
    
      <category term="Java" scheme="https://seriouszyx.github.io/tags/Java/"/>
    
  </entry>
  
</feed>
